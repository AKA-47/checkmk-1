#!/usr/bin/python
# -*- encoding: utf-8; py-indent-offset: 4 -*-
# +------------------------------------------------------------------+
# |             ____ _               _        __  __ _  __           |
# |            / ___| |__   ___  ___| | __   |  \/  | |/ /           |
# |           | |   | '_ \ / _ \/ __| |/ /   | |\/| | ' /            |
# |           | |___| | | |  __/ (__|   <    | |  | | . \            |
# |            \____|_| |_|\___|\___|_|\_\___|_|  |_|_|\_\           |
# |                                                                  |
# | Copyright Mathias Kettner 2018             mk@mathias-kettner.de |
# +------------------------------------------------------------------+
#
# This file is part of Check_MK.
# The official homepage is at http://mathias-kettner.de/check_mk.
#
# check_mk is free software;  you can redistribute it and/or modify it
# under the  terms of the  GNU General Public License  as published by
# the Free Software Foundation in version 2.  check_mk is  distributed
# in the hope that it will be useful, but WITHOUT ANY WARRANTY;  with-
# out even the implied warranty of  MERCHANTABILITY  or  FITNESS FOR A
# PARTICULAR PURPOSE. See the  GNU General Public License for more de-
# tails. You should have  received  a copy of the  GNU  General Public
# License along with GNU Make; see the file  COPYING.  If  not,  write
# to the Free Software Foundation, Inc., 51 Franklin St,  Fifth Floor,
# Boston, MA 02110-1301 USA.
import json


def docker_size_to_bytes(size_string):
    if size_string.endswith('GB'):
        return int(float(size_string[:-2]) * 10**9)
    if size_string.endswith('MB'):
        return int(float(size_string[:-2]) * 10**6)
    if size_string.endswith('kB'):
        return int(float(size_string[:-2]) * 10**3)
    return float(size_string[:-1])


def parse_docker_node_info(info):
    try:
        return json.loads(":".join(info[0]))
    except ValueError:
        pass

    parsed = {}
    prefix = ""
    for row in info:
        if not row:
            continue
        # ignore misssing keys / pad lines that are not of "key: value" type
        if len(row) == 1:
            row.append('')
        key = row[0].strip()
        value = ':'.join(row[1:]).strip()
        # indented keys are prefixed by the last not indented key
        # this does the right thing in the cases used below.
        indent = len(row[0]) - len(key)
        if indent == 0:
            parsed[key] = value
            prefix = key
        else:
            parsed[prefix + key] = value

    return parsed


def _parse_docker_node_disk_usage_dict(data):
    key = data.pop('Type').lower()

    act = data.get('Active')
    if act is not None:
        data['Active'] = int(act) if act else 0

    tc = data.get('TotalCount') or data.get('Total')
    if tc is not None:
        data['TotalCount'] = int(tc) if tc else 0

    sz = data.get('Size')
    if sz is not None:
        data['Size'] = docker_size_to_bytes(sz)

    rc = data.get('Reclaimable')
    if rc is not None:
        reclaimable = rc.split(' ')[0]    # discard percentage
        data['Reclaimable'] = docker_size_to_bytes(reclaimable)

    return key, data


def parse_docker_node_disk_usage(info):
    try:
        data_dicts = [json.loads(" ".join(line)) for line in info]
    except ValueError:
        header = [field.title() for field in info[0]]
        data_dicts = [{k: v for k, v in zip(header, row)}
                      for row in info[1:]]

    return dict(map(_parse_docker_node_disk_usage_dict, data_dicts))


def _split_subsections(info):
    subname = ''
    subsections = {}
    for row in info:
        if not row:
            continue
        if row[0].startswith('[[[') and row[0].endswith(']]]'):
            subname = row[0].strip('[]')
            continue
        subsections.setdefault(subname,  []).append(row)
    return subsections


def _parse_subsection_images(subinfo):
    '''parse output of "docker images"'''
    parsed = {}
    for row in subinfo:
        data = json.loads(" ".join(row))
        parsed.setdefault(data["ID"], data)
    return parsed


def _parse_subsection_labels(subinfo):
    return [json.loads(" ".join(row)) for row in subinfo]


def _parse_subsection_containers(subinfo):
    parsed = {}
    for row in subinfo:
        data = json.loads(" ".join(row))

        image_name = data["Image"]
        if ":" in image_name:
            data["Repository"], data["Tag"] = image_name.split(":", 1)
        else:
            data["Repository"], data["Tag"] = image_name, "latest"
        parsed[data["ID"]] = data
    return parsed


def parse_docker_node_images(info):
    '''parse output of <<<docker_node_images>>>

    $ echo "[[[images]]]"
    $ docker images
    $ echo "[[[image_labels]]]"
    $ IMAGE_IDS=$(docker images ls | awk 'BEGIN {ORF=" "} NR>1 {print $3}')
    $ docker image inspect "$IMAGE_IDS"
    $ echo "[[[containers]]]"
    $ docker ps --all
    '''
    subsections = _split_subsections(info)

    images = _parse_subsection_images(subsections.get("images", []))
    label_data = _parse_subsection_labels(subsections.get("images_labels", []))
    containers = _parse_subsection_containers(subsections.get("containers", []))

    for image_id, labels in label_data:
        image = images.get(image_id)
        if None not in (image_id, labels, image):
            image.setdefault("__labels__", {}).update(labels)

    mapping = {(i['Repository'], i['Tag']): i['ID'] for i in images}
    for c in containers:
        image_id = mapping.get((c["Repository"], c["Tag"]))
        image = images.get(image_id)
        if image is not None:
            image.setdefault("__containers__", []).append(c)

        lab = (p.split("=", 1) for p in c.get("Labels", []).split(","))
        c["Labels"] = list(lab)

    return {"images": images, "containers": containers}

