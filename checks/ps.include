#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (C) 2019 tribe29 GmbH - License: GNU General Public License v2
# This file is part of Checkmk (https://checkmk.com). It is subject to the terms and
# conditions defined in the file COPYING, which is part of this source code package.

from cmk.base.plugins.agent_based.utils.ps import (
    ps_info,
    ps_info_tuple,
    minn,
    maxx,
    replace_service_description,
    process_attributes_match,
    process_matches,
    format_process_list,
    parse_ps_time,
    ps_cleanup_params,
    cpu_rate,
)

GRAB_USER = False

factory_settings["ps_default_levels"] = {
    "levels": (1, 1, 99999, 99999),
}


def ps_wato_configured_inventory_rules(invrules):
    inventory_specs = []
    for value in host_extra_conf(host_name(), invrules):
        default_params = value.get('default_params', value)
        if "cpu_rescale_max" not in default_params:
            default_params["cpu_rescale_max"] = None

        inventory_specs.append((
            value['descr'],
            value.get('match'),
            value.get('user'),
            value.get('cgroup', (None, False)),
            value.get('label', {}),
            default_params,
        ))

    return inventory_specs


def inventory_ps_common(invrules, parsed):
    inventory_specs = ps_wato_configured_inventory_rules(invrules)

    inventory = []
    inventory_labels = []
    for line in parsed:
        for servicedesc, pattern, userspec, cgroupspec, labels, default_params in inventory_specs:
            # First entry in line is the node name or None for non-clusters
            process_info, command_line = line[1], line[2:]
            if not process_attributes_match(process_info, userspec, cgroupspec):
                continue
            matches = process_matches(command_line, pattern)
            if not matches:
                continue  # skip not matched lines

            # User capturing on rule
            if userspec == GRAB_USER:
                i_userspec = process_info.user
            else:
                i_userspec = userspec

            i_servicedesc = servicedesc.replace("%u", i_userspec or "")

            # Process capture
            match_groups = matches.groups() if hasattr(matches, 'groups') else ()

            i_servicedesc = replace_service_description(i_servicedesc, match_groups, pattern)

            # Problem here: We need to instantiate all subexpressions
            # with their actual values of the found process.
            inv_params = {
                "process": pattern,
                "match_groups": match_groups,
                "user": i_userspec,
                "cgroup": cgroupspec,
            }

            # default_params is either a clean dict with optional
            # parameters to set as default or - from version 1.2.4 - the
            # dict from the rule itself. In the later case we need to remove
            # the keys that do not specify default parameters
            for key, value in default_params.items():
                if key not in ("descr", "match", "user", "perfdata"):
                    inv_params[key] = value

            inv = (i_servicedesc, inv_params)

            if inv not in inventory:
                inventory.append(inv)
                inventory_labels.append(HostLabels(*[HostLabel(k, v) for k, v in labels.items()]))

    return inventory + inventory_labels


def check_ps_common(item, params, parsed, cpu_cores=1, info_name="Processes", total_ram=None):
    params = ps_cleanup_params(params)

    processes = check_ps_process_capture(parsed, params, cpu_cores)

    yield ps_count_check(processes, params, info_name)

    for memory_state in memory_check(processes, params):
        yield memory_state

    if processes.resident_size and "resident_levels_perc" in params:
        yield memory_perc_check(processes, params, total_ram)

    # CPU
    if processes.count:
        yield cpu_check(processes.percent_cpu, item, params)

    if "single_cpulevels" in params:
        for ps_state in individual_process_check(processes, params):
            yield ps_state

    # only check handle_count if provided by wmic counters
    if processes.handle_count:
        yield handle_count_check(processes, params)

    if processes.min_elapsed is not None:
        yield from uptime_check(processes, params)

    if params.get("process_info", None):
        infotext = "\n" + format_process_list(processes, params["process_info"] == "html")
        yield 0, infotext


def ps_count_check(processes, params, info_name):
    warnmin, okmin, okmax, warnmax = params["levels"]

    state, infotext, perfdata = check_levels(processes.count,
                                             "count", (okmax + 1, warnmax + 1, okmin, warnmin),
                                             human_readable_func=int,
                                             boundaries=(0, None),
                                             infoname=info_name)

    if processes.running_on_nodes:
        infotext += " [running on %s]" % ", ".join(sorted(processes.running_on_nodes))

    return state, infotext, perfdata


def memory_check(processes, params):
    """Check levels for virtual and physical used memory"""
    for size, title, levels, metric in [
        (processes.virtual_size, "virtual", "virtual_levels", "vsz"),
        (processes.resident_size, "physical", "resident_levels", "rss"),
    ]:
        if size == 0:
            continue

        warn_levels, crit_levels = params.get(levels, (None, None))
        status, info_text, perf_data = check_levels(size * 1024,
                                                    None, (warn_levels, crit_levels),
                                                    human_readable_func=get_bytes_human_readable,
                                                    infoname=title)
        yield status, info_text, [(metric, size, warn_levels, crit_levels)]


def memory_perc_check(processes, params, total_ram):
    """Check levels that are in percent of the total RAM of the host"""
    if not total_ram:
        return 3, "percentual RAM levels configured, but total RAM is unknown"

    resident_perc = 100 * float(processes.resident_size * 1024) / total_ram
    return check_levels(resident_perc,
                        None,
                        params["resident_levels_perc"],
                        human_readable_func=get_percent_human_readable,
                        infoname="Percentage of total RAM")


def cpu_check(percent_cpu, item, params):
    """Check levels for cpu utilization from given process"""

    infotext = "CPU"
    warn_cpu, crit_cpu = params.get("cpulevels", (None, None, None))[:2]
    perf_data = [("pcpu", percent_cpu, warn_cpu, crit_cpu)]

    # CPU might come with previous
    if "cpu_average" in params:
        infotext = "CPU: %s" % get_percent_human_readable(percent_cpu)
        now = time.time()
        avg_cpu = get_average("ps.%s.cpu" % item, now, percent_cpu, params["cpu_average"], False)
        infotext += ", %d min average" % params["cpu_average"]
        perf_data.append(("pcpuavg", avg_cpu, warn_cpu, crit_cpu, 0, params["cpu_average"]))
        percent_cpu = avg_cpu  # use this for level comparison

    state, infotext, _ = check_levels(percent_cpu,
                                      None, (warn_cpu, crit_cpu),
                                      human_readable_func=get_percent_human_readable,
                                      infoname=infotext)
    return state, infotext, perf_data


def individual_process_check(processes, params):
    levels = params["single_cpulevels"]
    for p in processes:
        cpu_usage, name, pid = 0.0, None, None

        for the_item, (value, _unit) in p:
            if the_item == "name":
                name = value
            if the_item == "pid":
                pid = value
            elif the_item.startswith("cpu usage"):
                cpu_usage += value

        process_description = name + " with PID %s CPU" % pid if pid else ""
        state, infotext, _ = check_levels(cpu_usage,
                                          None,
                                          levels,
                                          human_readable_func=get_percent_human_readable,
                                          infoname=process_description)
        if state:
            yield state, infotext


def uptime_check(times, params):
    """Check how long the process is running"""
    if times.min_elapsed == times.max_elapsed:
        yield check_levels(
            times.min_elapsed,
            None,
            params.get("max_age", (None, None)) + params.get("min_age", (None, None)),
            human_readable_func=get_age_human_readable,
            infoname="running for",
        )
    else:
        yield check_levels(
            times.min_elapsed,
            None,
            (None, None) + params.get("min_age", (None, None)),
            human_readable_func=get_age_human_readable,
            infoname="youngest running for",
        )
        yield check_levels(
            times.max_elapsed,
            None,
            params.get("max_age", (None, None)),
            human_readable_func=get_age_human_readable,
            infoname="oldest running for",
        )


def handle_count_check(processes, params):
    return check_levels(processes.handle_count,
                        "process_handles",
                        params.get("handle_count", (None, None)),
                        human_readable_func=int,
                        infoname="process handles")


class ProcessAggregator(object):
    """Collects information about all instances of monitored processes"""
    def __init__(self, cpu_cores, params):
        self.cpu_cores = cpu_cores
        self.params = params
        self.virtual_size = 0
        self.resident_size = 0
        self.handle_count = 0
        self.percent_cpu = 0.0
        self.max_elapsed = None
        self.min_elapsed = None
        self.processes = []
        self.running_on_nodes = set()

    def __getitem__(self, item):
        return self.processes[item]

    @property
    def count(self):
        return len(self.processes)

    def append(self, process):
        self.processes.append(process)

    def core_weight(self, is_win):
        cpu_rescale_max = self.params.get('cpu_rescale_max')

        # Rule not set up, only windows scaled
        if cpu_rescale_max is None and not is_win:
            return 1.0

        # Current rule is set. Explicitly ask not to divide
        if cpu_rescale_max is False:
            return 1.0

        # Use default of division
        return 1.0 / self.cpu_cores

    def lifetimes(self, process_info, process):
        # process_info.cputime contains the used CPU time and possibly,
        # separated by /, also the total elapsed time since the birth of the
        # process.
        if '/' in process_info.cputime:
            elapsed_text = process_info.cputime.split('/')[1]
        else:
            # uptime is a windows only value, introduced in Werk 4029. For
            # future consistency should be moved to the cputime entry and
            # separated by a /
            if process_info.uptime:
                elapsed_text = process_info.uptime
            else:
                elapsed_text = None

        if elapsed_text:
            elapsed = parse_ps_time(elapsed_text)
            self.min_elapsed = minn(self.min_elapsed or elapsed, elapsed)
            self.max_elapsed = maxx(self.max_elapsed, elapsed)

            now = time.time()
            creation_time_unix = int(now - elapsed)
            if creation_time_unix != 0:
                process.append((
                    "creation time",
                    (get_timestamp_human_readable(creation_time_unix), ""),
                ))

    def cpu_usage(self, process_info, process):

        now = time.time()

        pcpu_text = process_info.cputime.split('/')[0]

        if ":" in pcpu_text:  # In linux is a time
            total_seconds = parse_ps_time(pcpu_text)
            pid = process_info.process_id
            cputime = cpu_rate("ps_stat.pcpu.%s" % pid, now, total_seconds)

            pcpu = cputime * 100 * self.core_weight(is_win=False)
            process.append(("pid", (pid, "")))

        # windows cpu times
        elif process_info.usermode_time and process_info.kernelmode_time:
            pid = process_info.process_id

            user_per_sec = cpu_rate("ps_wmic.user.%s" % pid, now, int(process_info.usermode_time))
            kernel_per_sec = cpu_rate("ps_wmic.kernel.%s" % pid, now,
                                      int(process_info.kernelmode_time))

            if not all([user_per_sec, kernel_per_sec]):
                user_per_sec = 0
                kernel_per_sec = 0

            core_weight = self.core_weight(is_win=True)
            user_perc = user_per_sec / 100000.0 * core_weight
            kernel_perc = kernel_per_sec / 100000.0 * core_weight
            pcpu = user_perc + kernel_perc
            process.append(("cpu usage (user space)", (user_perc, "%")))
            process.append(("cpu usage (kernel space)", (kernel_perc, "%")))
            process.append(("pid", (pid, "")))

        else:  # Solaris, BSD, aix cpu times
            if pcpu_text == '-':  # Solaris defunct
                pcpu_text = 0.0
            pcpu = float(pcpu_text) * self.core_weight(is_win=False)

        self.percent_cpu += pcpu
        process.append(("cpu usage", (pcpu, "%")))

        if process_info.pagefile:
            process.append(("pagefile usage", (process_info.pagefile, "")))

        if process_info.handles:
            self.handle_count += int(process_info.handles)
            process.append(("handle count", (int(process_info.handles), "")))


def check_ps_process_capture(parsed, params, cpu_cores):

    ps_aggregator = ProcessAggregator(cpu_cores, params)

    userspec = params.get("user")
    cgroupspec = params.get("cgroup", (None, False))

    for line in parsed:
        node_name, process_line = line[0], line[1:]
        process_info, command_line = process_line[0], process_line[1:]

        if not process_attributes_match(process_info, userspec, cgroupspec):
            continue

        if not process_matches(command_line, params.get("process"), params.get('match_groups')):
            continue

        process = []

        if node_name is not None:
            ps_aggregator.running_on_nodes.add(node_name)

        if command_line:
            process.append(("name", (command_line[0], "")))

        # extended performance data: virtualsize, residentsize, %cpu
        if all(process_info[1:4]):
            process.append(("user", (process_info.user, "")))
            process.append(("virtual size", (int(process_info.virtual), "kB")))
            process.append(("resident size", (int(process_info.physical), "kB")))

            ps_aggregator.virtual_size += int(process_info.virtual)  # kB
            ps_aggregator.resident_size += int(process_info.physical)  # kB

            ps_aggregator.lifetimes(process_info, process)
            ps_aggregator.cpu_usage(process_info, process)

        include_args = params.get("process_info_arguments", 0)
        if include_args:
            process.append(("args", (' '.join(command_line[1:])[:include_args], "")))

        ps_aggregator.append(process)

    return ps_aggregator
